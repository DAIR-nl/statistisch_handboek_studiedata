
---
title: "Ongepaarde t-toets"
author: "© `r format(Sys.time(), '%Y')`, SURF Versnellingsagenda - Statistisch Handboek Hoger Onderwijs"
date: "`r format(Sys.time(), '%d-%m-%Y')`"
output:
  html_document:
    theme: lumen
    toc: yes
    toc_float: 
      collapsed: FALSE 
    number_sections: true
  keywords: [statistisch handboek, studiedata]
---

<style>
`r htmltools::includeHTML(paste0(here::here(),"/01. Includes/css/Stylesheet_SHHO.css"))`
</style>

```{r header, include = FALSE, echo = TRUE, results='asis'} 
paste0(here::here(),"/01. Includes/code/Header.R")
```

<!-- ## OPENBLOK: Functiedefinities.R -->
```{r functiedefinities,include=FALSE, echo=TRUE}
library(stringr)
Round_and_format <- function(x, digits = 2) {
  x <- as.character(round(x, digits))
  x <- str_replace(x, "[.]", ",")
  return(x)
}
library(reticulate)
knitr::knit_engines$set(python = reticulate::eng_python)
```
<!-- ## /BLOK: Functiedefinities.R -->

<!-- ## OPENBLOK: Data-aanmaken.R -->
```{r aanmaken data, include=FALSE, echo=TRUE}
RNGkind(sample.kind = "Rounding")
set.seed(1)

mu <- 6.3
sigma <- 1.2
Cijfers_2010 <- rnorm(180, mu, sigma)
Cijfers_2010 <- Cijfers_2010[Cijfers_2010 <= 10 & Cijfers_2010 >= 1]
Cijfers_2010 <- sapply(Cijfers_2010, round, 3)

mu <- 6.3
sigma <- 1.2
Cijfers_2010_n30 <- rnorm(30, mu, sigma)
Cijfers_2010_n30 <- Cijfers_2010_n30[Cijfers_2010_n30 <= 10 & Cijfers_2010_n30 >= 1]
Cijfers_2010_n30 <- sapply(Cijfers_2010_n30, round, 3)

mu <- 6.45
sigma <- 1.2
Cijfers_2011 <- rnorm(160, mu, sigma)
Cijfers_2011 <- Cijfers_2011[Cijfers_2011 <= 10 & Cijfers_2011 >= 1]
Cijfers_2011 <- sapply(Cijfers_2011, round, 3)

mu <- 6.45
sigma <- 1.2
Cijfers_2011_n30 <- rnorm(30, mu, sigma)
Cijfers_2011_n30 <- Cijfers_2011_n30[Cijfers_2011_n30 <= 10 & Cijfers_2011_n30 >= 1]
Cijfers_2011_n30 <- sapply(Cijfers_2011, round, 3)

Cijfers <- c(Cijfers_2010, Cijfers_2011)
Cohort <- c(replicate(180, 2010), replicate(160, 2011))
Cijfers_gem <- data.frame(Cijfers, Cohort)

```
<!-- ## /BLOK: Data-aanmaken.R -->
```{r opmerking, include=FALSE, eval=FALSE}
# linken naar de Mann-Whitney U toets  
```

# Toepassing
Gebruik de *ongepaarde t-toets* om de gemiddelden van twee onafhankelijke groepen te vergelijken.[^1]

# Onderwijscasus
<div id = "casus">
Vanaf 2011 heeft de opleiding Taalwetenschap een Bindend Studieadvies (BSA) die de selectiviteit van het eerste jaar moet vergroten. Zij vraagt zich af of het gemiddelde cijfer van de opleiding Taalwetenschap op 1 februari, na invoering van het BSA, veranderd is. De data is beschikbaar voor het cohort gestart in 2010 en voor het cohort gestart in 2011.

H~0~: Het gemiddelde tentamencijfer dat de studenten halen aan de opleiding Taalwetenschap is niet veranderd na de invoer van het BSA, µ~0~ = µ~1~  

H~A~: Het gemiddelde tentamencijfer dat de studenten halen aan de opleiding Taalwetenschap is veranderd na de invoer van het BSA, µ~0~ ≠ µ~1~
</div>

# Assumpties
Voor een valide resultaat moeten de data aan een aantal voorwaarden voldoen voordat de toets uitgevoerd kan worden.

## Normaliteit 
De *t-toets* gaat ervan uit dat de data van de steekproef normaal verdeeld zijn. Ga er bij een n > 100 vanuit dat de t-toets robuust genoeg is om uit te voeren zonder dat de data een normale verdeling volgen.[^2] 

Controleer de assumptie van normaliteit met de volgende stappen:  
1. Controleer de data visueel met een histogram, een boxplot of een Q-Q plot.   
2. Toets of de data normaal verdeeld zijn met de *Kolmogorov-Smirnov test* of bij een kleinere steekproef (n < 50) met de *Shapiro-Wilk test*.[^3]<sup>, </sup>[^4]  

Als blijkt dat de data niet normaal verdeeld zijn, transformeer de data eventueel en bepaal daarna of deze wel normaal verdeeld zijn.

Als er geen sprake is van normaliteit gebruik de *Mann-Whitney U toets*, ook bekend als de *Wilcoxon rank-sum toets*.[^5]<sup>, </sup>[^6]  

## Homogeniteit van varianties 
Toets met de *Levene’s Test (for equality of variance)* of de spreiding van iedere groep globaal hetzelfde is. Bij een *p* < 0,05 is de spreiding van de groepen statistisch significant verschillend.[^7]

# Effectmaat
Bereken de effectmaat om te bepalen of de gevonden p-waarde van een t-toets betekenisvol is. Een veel gebruikte effectmaat is Cohen's *d*. Cohen's *d* geeft de sterkte van het effect van een onafhankelijke variabele op een afhankelijke variabele weer. Een indicatie om *d* te interpreteren is: rond 0,3 is het een klein effect, rond 0,5 is het een gemiddeld effect en rond 0,8 is het een groot effect.[^8]

# Uitvoering
Er is een dataset ingeladen met gemiddelde cijfers van tweedejaarsstudenten bij de opleiding Taalwetenschap: `Cijfers_gem`. De data bevatten cijfers van 180 studenten begonnen in 2010 en cijfers van 160 studenten begonnen in 2011.

## De data bekijken
Gebruik `<dataframe>.head()` en `<dataframe>.tail()` om de structuur van de data te bekijken.
<!-- ## OPENBLOK: Data-bekijken.py -->
```{python, include=FALSE}
import pandas as pd
dfCijfers_gem = pd.DataFrame(r.Cijfers_gem)
```

```{python data bekijken-1, collapse = TRUE}
## Eerste 6 observaties
print(dfCijfers_gem.head(6))
```

```{python data bekijken-2, collapse = TRUE}
## Laatste 6 observaties
print(dfCijfers_gem.tail(6))
```
<!-- ## /BLOK: Data-bekijken.py -->

Selecteer beide groepen en sla deze op in een vector om deze makkelijker aan te kunnen roepen. 
<!-- ## OPENBLOK: Data-selecteren.py -->
```{python data selecteren}
Cijfers_2010 = dfCijfers_gem[dfCijfers_gem['Cohort'] == 2010]['Cijfers']
Cijfers_2011 = dfCijfers_gem[dfCijfers_gem['Cohort'] == 2011]['Cijfers']
```
<!-- ## /BLOK: Data-selecteren.py -->

Inspecteer de data met `len()`, `np.mean()` en `np.sqrt(np.var())`, door deze aan te roepen uit de library `numpy`.

<!-- ## OPENBLOK: Data-beschrijven-inladen.py -->
```{python}
# Om het gemiddelde en de standaard deviatie te berekenen, hebben we de library 'numpy' nodig
import numpy as np
```
<!-- ## OPENBLOK: Data-beschrijven-inladen.py -->

<div class="col2">
<!-- ## OPENBLOK: Data-beschrijven-1.py -->
```{python Data beschrijven 1, collapse=TRUE}
## Aantallen, gemiddelde en standaarddeviatie 2010
print(len(Cijfers_2010))
print(np.mean(Cijfers_2010))
print(np.sqrt(np.var(Cijfers_2010)))
```
<!-- ## /BLOK: Data-beschrijven-1.py -->

```{r Var beschrijven t0, include=FALSE, echo=TRUE}
vN_t0 <- Round_and_format(length(Cijfers_2010))
vMean_t0 <- Round_and_format(mean(Cijfers_2010))
vSD_t0 <-Round_and_format(sd(Cijfers_2010))
```

<!-- ## OPENBLOK: Data-beschrijven-2.py -->
```{python Data beschrijven 2, collapse=TRUE}
## Aantallen, gemiddelde en standaarddeviatie 2011
print(len(Cijfers_2011))
print(np.mean(Cijfers_2011))
print(np.sqrt(np.var(Cijfers_2011)))
```
<!-- ## /BLOK: Data-beschrijven-2.R -->

```{r Var beschrijven t1, include=FALSE, echo=TRUE}
vN_t1 <- Round_and_format(length(Cijfers_2011))
vMean_t1 <- Round_and_format(mean(Cijfers_2011))
vSD_t1 <-Round_and_format(sd(Cijfers_2011))
```
</div>

* Gemiddeld tentamencijfer 2010 (standaarddeviatie): `r vMean_t0` (`r vSD_t0`). *n* = `r vN_t0`.
* Gemiddeld tentamencijfer 2011 (standaarddeviatie): `r vMean_t1` (`r vSD_t1`). *n* = `r vN_t1`.

## Visuele inspectie van normaliteit
Geef normaliteit visueel weer met een histogram, Q-Q plot of boxplot.

### Histogram
<!-- ## OPENBLOK: Histogram.py -->
```{python histogram}
## Histogram met matplotlib
import matplotlib.pyplot as plt
fig = plt.figure()
sub1 = fig.add_subplot(1, 2, 1)
title1 = plt.title("2010")
hist1 = plt.hist(Cijfers_2010, density = True, edgecolor = "black", bins = 9)

sub2 = fig.add_subplot(1, 2, 2)
title2 = plt.title("2011")
hist2 = plt.hist(Cijfers_2011, density = True, edgecolor = "black", bins = 9)

main = fig.suptitle('Taalwetenschap gemiddelde cijfers voor en na de BSA')
plt.show()
```
<!-- ## /BLOK: Histogram.py -->

Beide histogrammen laten een Bell Curve zien vergelijkbaar met een normale verdeling: veel waardes liggen rondom het gemiddelde.  

### Q-Q plot
Als over het algemeen de meeste datapunten op de lijn liggen, kan aangenomen worden dat de data normaal verdeeld zijn.
<div class ="col-container">
  <div class = "col"> 
<!-- ## OPENBLOK: QQplot-t1.py -->
```{python QQplot-t1}
import scipy.stats as stats
qq = stats.probplot(Cijfers_2010, dist="norm", plot=plt)
title = plt.title("Normaal Q-Q plot van tentamencijfers 2010")
xlab = plt.xlabel("Theoretische kwantielen")
ylab = plt.ylabel("Kwantielen in data")
plt.show()
```
<!-- ## /BLOK: QQplot-t1.R -->
  </div>
  <div class = "col">
<!-- ## OPENBLOK: QQplot-t2.py -->
```{python QQplot-t2}
import scipy.stats as stats
qq = stats.probplot(Cijfers_2011, dist="norm", plot=plt)
title = plt.title("Normaal Q-Q plot van tentamencijfers 2011")
xlab = plt.xlabel("Theoretische kwantielen")
ylab = plt.ylabel("Kwantielen in data")
plt.show()
```
<!-- ## /BLOK: QQplot-t2.py -->
  </div>
</div>
Bij beide groepen liggen de meeste punten op de lijn behalve bij de uiteinden.

### Boxplot
De box geeft de middelste 50% van de tentamencijfers weer. De zwarte lijn binnen de box is de mediaan. In de staarten zitten de eerste 25% en de laatste 25%. Cirkels visualiseren mogelijke uitbijters.[^9] 

<!-- ## OPENBLOK: Boxplot.py -->
```{python boxplot}
fig, ax = plt.subplots()
box = ax.boxplot([Cijfers_2010, Cijfers_2011], labels = ["2010", "2011"])
title = plt.title("Tentamencijfers Taalwetenschap voor en na de BSA")
plt.show()
```
<!-- ## /BLOK: Boxplot.py -->

De boxplotten geven de spreiding weer van het gemiddelde tentamencijfer voor de BSA en na de BSA. De boxplotten en de staarten lijken symmetrisch, dit kan een teken zijn van normaal verdeelde data. Het cohort van 2011 heeft een aantal mogelijke uitbijters.[^10] 

## Toetsen van normaliteit
Om te controleren of de data normaal verdeeld zijn, kan de normaliteit getoets worden. Twee veelgebruikte toetsen zijn: de *Kolmogorov-Smirnov test* en de *Shapiro-Wilk test*.

### Kolmogorov-Smirnov
De *Kolmogorov-Smirnov test* toetst het verschil tussen twee verdelingen. Standaard toetst deze test het verschil tussen een normale verdeling en de verdeling van de steekproef. De Lilliefors correctie wordt gebruikt als het gemiddelde niet 0 is en de standaardafwijking niet 1 is. Als de p < 0,05 is, is de verdeling van de data statistisch significant verschillend van de normale verdeling.

<!-- ## /BLOK: Library-nortest inladen.py -->
```{python}
import statsmodels.stats.api
```
<!-- ## /BLOK: Library-nortest inladen.py -->

<div class="col-container">
  <div class = "col">
<!-- ## OPENBLOK: Lilliefors-test-1.py -->
``` {python Lilliefors Test-1, warning=FALSE}
print(statsmodels.stats.api.lilliefors(Cijfers_2010))
```
<!-- ## /BLOK: Lilliefors-test-1.py -->
  </div>
  <div class = "col">
<!-- ## OPENBLOK: Lilliefors-test-2.py -->
``` {python Lilliefors Test-2, warning=FALSE}
print(statsmodels.stats.api.lilliefors(Cijfers_2011))
```
<!-- ## /BLOK: Lilliefors-test-2.py -->
  </div>
</div>

Bij deze casus is van beide groepen de p-waarde > 0,05; er is geen statistisch significant verschil gevonden tussen de verdeling van de steekproef en de normale verdeling. De *ongepaarde t-toets* kan uitgevoerd worden.

### Shapiro-Wilk Test
De *Shapiro-Wilk test* is een soortgelijke test als de *Kolmogorov-Smirnov test* en wordt vooral gebruikt bij kleine steekproeven.  Als de p-waarde < 0,05 is de verdeling van de data statistisch significant verschillend van de normale verdeling. 

Er zijn 2 steekproeven van `Cijfers_gem` ingeladen: `Cijfers_2010_n30` en `Cijfers_2011_n30`. Beide steekproeven bevatten `r length(Cijfers_2010_n30)` studenten
<div class = "col-container">
  <div class="col">
<!-- ## OPENBLOK: Shapiro-Wilk-test-1.py -->
``` {python Shapiro-Wilk Test-1, warning=FALSE}
print(stats.shapiro(r.Cijfers_2011_n30))
```
<!-- ## /BLOK: Shapiro-Wilk-test-1.py -->
  </div>
  <div class="col">
<!-- ## OPENBLOK: Shapiro-Wilk-test-2.py -->
``` {python Shapiro-Wilk Test-2, warning=FALSE}
print(stats.shapiro(r.Cijfers_2010_n30))
```
<!-- ## /BLOK: Shapiro-Wilk-test-2.py -->
  </div>
</div>
De p-waarde is *p* > 0,05, dus er is geen statistisch significant verschil gevonden tussen de verdeling van de steekproef en de normale verdeling. De *ongepaarde t-toets* kan uitgevoerd worden.

## Test assumpties: Levene's test
Test met de Levene's test de homogeniteit van varianties. Als uit de *Levene's test* komt dat de steekproeven verschillen in variantie kan de *ongepaarde t-toets* met ongelijke varianties uitgevoerd worden. Gebruik hier weer het hele dataframe `Cijfers_gem`.

<!-- ## OPENBLOK: Levenes-test.py -->
```{python Levenes test}
print(stats.levene(Cijfers_2010, Cijfers_2011))
```
<!-- ## OPENBLOK: Levenes-test.py -->

<!-- ## /BLOK: Levenes-test.R -->
```{r Levenes test als object, echo = FALSE, warning=FALSE}
library(car)
L <- leveneTest(Cijfers_gem$Cijfers, Cijfers_gem$Cohort)
vF_waarde <- Round_and_format(L$`F value`[1])
vF_p <- Round_and_format(L$`Pr(>F)`[1])
vDF1 <- Round_and_format(L$`Df`[1])
vDF2 <- Round_and_format(L$`Df`[2])
```
<!-- ## /BLOK: Levenes-test.R -->
* *F*~`r vDF1`~~,~~`r vDF2`~ = `r vF_waarde`, p-waarde = `r vF_p` 
* p-waarde > 0,05, dus de groepen zijn niet significant verschillend in spreiding.  
* Vrijheidsgraden bestaan uit twee cijfers, het eerste cijfer (het aantal groepen - 1 = `r vDF1`) en het tweede cijfer (*n~2010~* + *n~2011~* - 2 = `r vDF2`)

## Ongepaarde t-toets
Voer een ongepaarde `t.test()` uit met `paired = FALSE` en `var.equal = TRUE`. Als uit de *Levene's test* komt dat de groepen verschillen in variantie, gebruik `var.equal = FALSE` .

De *ongepaarde t-toets* wordt uitgevoerd om de vraag te beantwoorden of het het gemiddelde tentamencijfer van de opleiding Taalwetenschap na invoering van het BSA veranderd is. De verwachting is dat de studenten hoger scoren, maar omdat het relevant om te weten of de studenten ook lager scoren na de invoering is er voor gekozen om tweezijdig te toetsen. 

<!-- ## OPENBLOK: T-test.py -->
```{python statistische toets}
print(stats.ttest_ind(Cijfers_2010, Cijfers_2011))
```
<!-- ## /BLOK: T-test.py -->

```{r T-test als object, echo = FALSE}
t <- t.test(Cijfers ~ Cohort, Cijfers_gem, paired = FALSE, var.equal = TRUE)
vT_waarde <- Round_and_format(t$statistic)
vN <- t$parameter+1
vDF <- t$parameter
vConf.int1 <- Round_and_format(t$conf.int[1])
vConf.int2 <- Round_and_format(t$conf.int[2])
vP <- Round_and_format(t$p.value)
```

* *t* ~`r vDF`~ = `r vT_waarde`, *p* = `r vP`
* Vrijheidsgraden, *df* = *n* -1 = `r vN`-1 = `r vDF`  
* p-waarde > 0,05, dus de H~0~ wordt niet verworpen [^11]
* 95%-betrouwbaarheidsinterval: bij het herhalen van het onderzoek zal in 95% van de gevallen de µ in het interval vallen. In deze casus is het interval tussen `r vConf.int1` en `r vConf.int2`.
* Het gemiddelde van de steekproef in 2010: `r vMean_t0`
* Het gemiddelde van de steekproef in 2011: `r vMean_t1`

### Effectmaat: Cohen's d 
Wanneer p < 0,05 wordt de effectmaat berekend om te bepalen of de gevonden p-waarde betekenisvol is. In dit voorbeeld is de p > 0,05, dus is een effectmaat irrelevant. Hieronder laten we zien wat de stappen zouden zijn bij een p < 0,05.

Gebruik `cohen.d()` met `paired = FALSE` om het effect te meten.

<!-- ## OPENBLOK: Cohens-d-test.py -->
```{python}
def cohend(x, y):
  # import numpy
  import numpy as np
	
	# calculate the size of samples
  n1, n2 = len(x), len(y)
	
	# calculate the variance of the samples
  v1, v2 = np.var(x, ddof=1), np.var(y, ddof=1)
	
	# calculate the pooled standard deviation
  s = np.sqrt(((n1 - 1) * v1 + (n2 - 1) * v2) / (n1 + n2 - 2))
	
	# calculate the means of the samples
  m1, m2 = np.mean(x), np.mean(y)
	
	# calculate the effect size
  return (m1 - m2) / s
```

```{python}
print(cohend(Cijfers_2010, Cijfers_2011))
```
<!-- ## OPENBLOK: Cohens-d-test.py -->

```{r var Cohens d, echo = FALSE}
d <- cohen.d(Cijfers_2010, Cijfers_2011, paired = FALSE)
vD_waarde <- Round_and_format(d$estimate)
```
*d* = `r vD_waarde`. De sterkte van het effect van de tutor op het cijfer is verwaarloosbaar. 


# Rapportage
Een *ongepaarde t-toets* is uitgevoerd om te toetsen of het gemiddelde tentamencijfer is veranderd na de invoer van het BSA. Het verschil tussen het gemiddelde tentamencijfer van cohort 2010 (*M~2010~* = `r vMean_t0`, *SD~2010~* = `r vSD_t0`) en het gemiddelde tentamencijfer van cohort 2011 (*M~2011~* = `r vMean_t1`, *SD~2011~* = `r vSD_t1`) is statistisch niet significant, *t* ~`r vDF`~ = `r vT_waarde`, *p* > 0,05, zie tabel hieronder. Het 95% betrouwbaarheidsinterval voor het verschil tussen het gemiddelde van beide groepen is van `r vConf.int1` tot `r vConf.int2`. Het effect is minimaal, *d* = `r vD_waarde`.

Aan de hand van de resultaten kan geconcludeerd worden dat het gemiddelde tentamencijfer niet is veranderd na de invoer van het BSA. 

| Cohort   | N         | M            | SD         |
| -------- | --------- | ------------ | ---------- |
| 2010     | `r vN_t0` | `r vMean_t0` | `r vSD_t0` |
| 2011     | `r vN_t1` | `r vMean_t1` | `r vSD_t1` |

[^1]: Van Geloven, N. (25 mei 2016). *T-toets* [Wiki Statistiek Academisch Medisch Centrum](https://wikistatistiek.amc.nl/index.php/T-toets#ongepaarde_t-toets).
[^2]: Lumley, T., Diehr, P., Emerson, S., & Chen, L. (2002). Tthe importance of the normality assumption in large public health data sets. *Annu Rev Public Health, 23*, 151-69. doi: 10.1146/annurev.publheath.23.100901.140546 http://rctdesign.org/techreports/arphnonnormality.pdf 
[^3]: Laerd statistics. (2018). [Testing for Normality using SPSS Statistics](https://statistics.laerd.com/spss-tutorials/testing-for-normality-using-spss-statistics.php).
[^4]: Normaliteit. (14 juli 2014). [UvA Wiki Methodologiewinkel](https://wiki.uva.nl/methodologiewinkel/index.php/Normaliteit).
[^5]: Van Geloven, N. (13 maart 2018). *Mann-Whitney U toets* [Wiki Statistiek Academisch Medisch Centrum](https://wikistatistiek.amc.nl/index.php/Mann-Whitney_U_toets).
[^6]: De *Mann-Whitney U toets* maakt een rangschikking van de data. Hierdoor is de test verdelingsvrij en is normaliteit geen assumptie. Ook zijn uitbijters minder van invloed op het eindresultaat. Toch wordt er voor deze test minder vaak gekozen, dit komt doordat bij het maken van een rankschikking de data informatie verliest. Als de data wel normaal verdeeld zijn heeft de *Mann-Whitney U toets* minder onderscheidend vermogen, dan wanneer de *ongepaarde t-toets* uitgevoerd zou worden. 
[^7]: Van Geloven, N. (25 mei 2016). *One-way ANOVA* [Wiki Statistiek Academisch Medisch Centrum](https://wikistatistiek.amc.nl/index.php/One-way_ANOVA).
[^8]: Marshall, E., & Boggis, E. (2016). *The statistics tutor’s quick guide to commonly used statistical tests*. http://www.statstutor.ac.uk/resources/uploaded/tutorsquickguidetostatistics.pdf 
[^9]: Outliers (13 augustus 2016). [UvA Wiki Methodologiewinkel](https://wiki.uva.nl/methodologiewinkel/index.php/Outliers).
[^10]: Uitbijters kunnen bepalend zijn voor de uitkomst van toetsen. Bekijk of de uitbijters valide uitbijters zijn en niet een meetfout] of op een andere manier incorrect verkregen data. Het weghalen van uitbijters kan de uitkomst ook vertekenen, daarom is het belangrijk om verwijderde uitbijters te melden in een rapport. 
[^11]: In dit voorbeeld wordt uitgegaan van een waarschijnlijkheid van 95% en c.q. een p-waardegrens van 0,05. De grens is naar eigen inzicht aan te passen, hou hierbij rekening met type I en type II fouten.
